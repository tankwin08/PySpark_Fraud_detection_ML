{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble models - pyspark\n",
    "\n",
    "The code was partially borrowed from [here](http://people.stat.sc.edu/haigang/improvement.html).\n",
    "\n",
    "The variable importance can be used in other analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import  RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, VectorAssembler, VectorSlicer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()\n",
    "spark = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data\n",
    "## where: https://archive.ics.uci.edu/ml/machine-learning-databases/00222/\n",
    "\n",
    "data_file = './data/bank-additional/bank-additional-full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"delimiter\", \";\").csv(data_file,header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41188"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'int'),\n",
       " ('job', 'string'),\n",
       " ('marital', 'string'),\n",
       " ('education', 'string'),\n",
       " ('default', 'string'),\n",
       " ('housing', 'string'),\n",
       " ('loan', 'string'),\n",
       " ('contact', 'string'),\n",
       " ('month', 'string'),\n",
       " ('day_of_week', 'string'),\n",
       " ('duration', 'int'),\n",
       " ('campaign', 'int'),\n",
       " ('pdays', 'int'),\n",
       " ('previous', 'int'),\n",
       " ('poutcome', 'string'),\n",
       " ('emp.var.rate', 'double'),\n",
       " ('cons.price.idx', 'double'),\n",
       " ('cons.conf.idx', 'double'),\n",
       " ('euribor3m', 'double'),\n",
       " ('nr.employed', 'double'),\n",
       " ('y', 'string')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rename the column names\n",
    "df = df.toDF(*(c.replace('.', '_') for c in df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupBy('y').count().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = df.select(\"y\").distinct().withColumn(\"fraction\", lit(0.8)).rdd.collectAsMap()\n",
    "df_train = df.sampleBy('y',fractions,seed=17)\n",
    "df_test = df.subtract(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'month',\n",
       " 'day_of_week',\n",
       " 'duration',\n",
       " 'campaign',\n",
       " 'pdays',\n",
       " 'previous',\n",
       " 'poutcome',\n",
       " 'emp_var_rate',\n",
       " 'cons_price_idx',\n",
       " 'cons_conf_idx',\n",
       " 'euribor3m',\n",
       " 'nr_employed',\n",
       " 'y']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding and assembling\n",
    "encoding_var = [i[0] for i in df.dtypes if (i[1]=='string') & (i[0]!='y')]\n",
    "num_var = [i[0] for i in df.dtypes if ((i[1]=='int') | (i[1]=='double')) & (i[0]!='y')]\n",
    "\n",
    "'''from string to interger'''\n",
    "string_indexes = [StringIndexer(inputCol = c, outputCol = 'IDX_' + c, handleInvalid = 'keep') for c in encoding_var]\n",
    "'''from interger to binary vectors'''\n",
    "onehot_indexes = [OneHotEncoderEstimator(inputCols = ['IDX_' + c], outputCols = ['OHE_' + c]) for c in encoding_var]\n",
    "label_indexes = StringIndexer(inputCol = 'y', outputCol = 'label', handleInvalid = 'keep')\n",
    "\n",
    "\n",
    "## The input for the model should be binary vectors\n",
    "assembler = VectorAssembler(inputCols = num_var + ['OHE_' + c for c in encoding_var], outputCol = \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier,LogisticRegression, NaiveBayes\n",
    "\n",
    "rf = RandomForestClassifier(numTrees=20)\n",
    "xgb = GBTClassifier(maxIter= 10)\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.2)\n",
    "#nb = NaiveBayes(smoothing= 0.5, modelType=\"multinomial\")\n",
    "\n",
    "methods = {\"random forest\": rf,\n",
    "           \"logistic regression\": lr,\n",
    "          \"boosting tree\": xgb ##this needs to be different from others\n",
    "          #\"naive bayes\": nb\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.908785781708145\n",
      "0.8935541330413904\n",
      "0.9459866824566329\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "fitted_models ={}\n",
    "\n",
    "for method_name, method in methods.items():\n",
    "    \n",
    "    method.setPredictionCol(\"prediction_\" + method_name)\n",
    "    if method_name != \"boosting tree\":\n",
    "        method.setProbabilityCol(\"probability_\" + method_name)\n",
    "        method.setRawPredictionCol(\"raw_prediction_\" + method_name)\n",
    "        sel_col = \"probability_\" + method_name\n",
    "    else:\n",
    "        sel_col = \"probability\"\n",
    "    \n",
    "\n",
    "    pipe = Pipeline(stages = string_indexes + onehot_indexes + [assembler, label_indexes, method])\n",
    "    # need to keep fitted model somewhere\n",
    "    fitted_models[method_name] = pipe.fit(df_train)\n",
    "    df_test = fitted_models[method_name].transform(df_test)\n",
    "    \n",
    "    filter_col1 = [col for col in df_test.columns if col.startswith('IDX')]\n",
    "    filter_col2 = [col for col in df_test.columns if col.startswith('OHE')]\n",
    "    drop_cols = filter_col1 + filter_col2 + ['features','label']\n",
    "    \n",
    "    \n",
    "    \n",
    "    evaluator= BinaryClassificationEvaluator(rawPredictionCol=sel_col, metricName= \"areaUnderROC\")\n",
    "    print(evaluator.evaluate(df_test))\n",
    "    if method_name != list(methods.keys())[len(methods)-1]: ##if it is the last layer, we will not drop columns\n",
    "        df_test = df_test.drop(*drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second layer prediction\n",
    "\n",
    "To bulid a model on these probability columns and see how well it can predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_vars = [var for var in df_test.columns if var.startswith(\"probability\")]\n",
    "vs_second_layers = VectorAssembler(inputCols= prediction_vars, outputCol= \"second_layer_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_layer = RandomForestClassifier(featuresCol= \"second_layer_input\", labelCol= \"label\",  probabilityCol = \"second_layer_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier_563258491f72"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To aviod existig column problems\n",
    "method_name = 'RF2'\n",
    "\n",
    "second_layer.setPredictionCol(\"prediction_\" + method_name)\n",
    "second_layer.setProbabilityCol(\"probability_\" + method_name)\n",
    "second_layer.setRawPredictionCol(\"raw_prediction_\" + method_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = Pipeline(stages = [vs_second_layers, second_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_second_layer = pipe1.fit(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 =model_second_layer.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'month',\n",
       " 'day_of_week',\n",
       " 'duration',\n",
       " 'campaign',\n",
       " 'pdays',\n",
       " 'previous',\n",
       " 'poutcome',\n",
       " 'emp_var_rate',\n",
       " 'cons_price_idx',\n",
       " 'cons_conf_idx',\n",
       " 'euribor3m',\n",
       " 'nr_employed',\n",
       " 'y',\n",
       " 'raw_prediction_random forest',\n",
       " 'probability_random forest',\n",
       " 'prediction_random forest',\n",
       " 'raw_prediction_logistic regression',\n",
       " 'probability_logistic regression',\n",
       " 'prediction_logistic regression',\n",
       " 'IDX_job',\n",
       " 'IDX_marital',\n",
       " 'IDX_education',\n",
       " 'IDX_default',\n",
       " 'IDX_housing',\n",
       " 'IDX_loan',\n",
       " 'IDX_contact',\n",
       " 'IDX_month',\n",
       " 'IDX_day_of_week',\n",
       " 'IDX_poutcome',\n",
       " 'OHE_job',\n",
       " 'OHE_marital',\n",
       " 'OHE_education',\n",
       " 'OHE_default',\n",
       " 'OHE_housing',\n",
       " 'OHE_loan',\n",
       " 'OHE_contact',\n",
       " 'OHE_month',\n",
       " 'OHE_day_of_week',\n",
       " 'OHE_poutcome',\n",
       " 'features',\n",
       " 'label',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction_boosting tree',\n",
       " 'second_layer_input',\n",
       " 'raw_prediction_RF2',\n",
       " 'probability_RF2',\n",
       " 'prediction_RF2']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator1= BinaryClassificationEvaluator(rawPredictionCol=\"probability_\" + method_name, metricName= \"areaUnderROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9469240271736227\n"
     ]
    }
   ],
   "source": [
    "print(evaluator1.evaluate(df_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
